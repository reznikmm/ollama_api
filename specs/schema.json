{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Ollama API Schemas",
  "definitions": {
    "ModelOptions": {
      "type": "object",
      "description": "Runtime options that control text generation",
      "properties": {
        "seed": {
          "type": "integer",
          "description": "Random seed used for reproducible outputs"
        },
        "temperature": {
          "type": "number",
          "format": "float",
          "description": "Controls randomness in generation (higher = more random)"
        },
        "top_k": {
          "type": "integer",
          "description": "Limits next token selection to the K most likely"
        },
        "top_p": {
          "type": "number",
          "format": "float",
          "description": "Cumulative probability threshold for nucleus sampling"
        },
        "min_p": {
          "type": "number",
          "format": "float",
          "description": "Minimum probability threshold for token selection"
        },
        "stop": {
              "type": "array",
              "items": {
                "type": "string"
              },
          "description": "Stop sequences that will halt generation"
        },
        "num_ctx": {
          "type": "integer",
          "description": "Context length size (number of tokens)"
        },
        "num_predict": {
          "type": "integer",
          "description": "Maximum number of tokens to generate"
        }
      },
      "additionalProperties": true
    },
    "GenerateRequest": {
      "type": "object",
      "required": [
        "model"
      ],
      "properties": {
        "model": {
          "type": "string",
          "description": "Model name"
        },
        "prompt": {
          "type": "string",
          "description": "Text for the model to generate a response from"
        },
        "suffix": {
          "type": "string",
          "description": "Used for fill-in-the-middle models, text that appears after the user prompt and before the model response"
        },
        "images": {
          "type": "array",
          "items": {
            "type": "string",
            "description": "Base64-encoded images for models that support image input"
          }
        },
        "format": {
          "description": "Structured output format for the model to generate a response from. Supports either the string `\"json\"` or a JSON schema object.",
              "type": "object"
        },
        "system": {
          "description": "System prompt for the model to generate a response from",
          "type": "string"
        },
        "stream": {
          "description": "When true, returns a stream of partial responses",
          "type": "boolean",
          "default": true
        },
        "think": {
              "type": "string",
              "enum": [
                "high",
                "medium",
                "low"
              ],
          "description": "When true, returns separate thinking output in addition to content. Can be a boolean (true/false) or a string (\"high\", \"medium\", \"low\") for supported models."
        },
        "raw": {
          "type": "boolean",
          "description": "When true, returns the raw response from the model without any prompt templating"
        },
        "keep_alive": {
              "type": "string",
          "description": "Model keep-alive duration (for example `5m` or `0` to unload immediately)"
        },
        "options": {
          "$ref": "#/definitions/ModelOptions"
        },
        "logprobs": {
          "type": "boolean",
          "description": "Whether to return log probabilities of the output tokens"
        },
        "top_logprobs": {
          "type": "integer",
          "description": "Number of most likely tokens to return at each token position when logprobs are enabled"
        }
      }
    },
    "GenerateResponse": {
      "type": "object",
      "properties": {
        "model": {
          "type": "string",
          "description": "Model name"
        },
        "created_at": {
          "type": "string",
          "description": "ISO 8601 timestamp of response creation"
        },
        "response": {
          "type": "string",
          "description": "The model's generated text response"
        },
        "thinking": {
          "type": "string",
          "description": "The model's generated thinking output"
        },
        "done": {
          "type": "boolean",
          "description": "Indicates whether generation has finished"
        },
        "done_reason": {
          "type": "string",
          "description": "Reason the generation stopped"
        },
        "total_duration": {
          "type": "integer",
          "description": "Time spent generating the response in nanoseconds"
        },
        "load_duration": {
          "type": "integer",
          "description": "Time spent loading the model in nanoseconds"
        },
        "prompt_eval_count": {
          "type": "integer",
          "description": "Number of input tokens in the prompt"
        },
        "prompt_eval_duration": {
          "type": "integer",
          "description": "Time spent evaluating the prompt in nanoseconds"
        },
        "eval_count": {
          "type": "integer",
          "description": "Number of output tokens generated in the response"
        },
        "eval_duration": {
          "type": "integer",
          "description": "Time spent generating tokens in nanoseconds"
        },
        "logprobs": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/Logprob"
          },
          "description": "Log probability information for the generated tokens when logprobs are enabled"
        }
      }
    },
    "GenerateStreamEvent": {
      "type": "object",
      "properties": {
        "model": {
          "type": "string",
          "description": "Model name"
        },
        "created_at": {
          "type": "string",
          "description": "ISO 8601 timestamp of response creation"
        },
        "response": {
          "type": "string",
          "description": "The model's generated text response for this chunk"
        },
        "thinking": {
          "type": "string",
          "description": "The model's generated thinking output for this chunk"
        },
        "done": {
          "type": "boolean",
          "description": "Indicates whether the stream has finished"
        },
        "done_reason": {
          "type": "string",
          "description": "Reason streaming finished"
        },
        "total_duration": {
          "type": "integer",
          "description": "Time spent generating the response in nanoseconds"
        },
        "load_duration": {
          "type": "integer",
          "description": "Time spent loading the model in nanoseconds"
        },
        "prompt_eval_count": {
          "type": "integer",
          "description": "Number of input tokens in the prompt"
        },
        "prompt_eval_duration": {
          "type": "integer",
          "description": "Time spent evaluating the prompt in nanoseconds"
        },
        "eval_count": {
          "type": "integer",
          "description": "Number of output tokens generated in the response"
        },
        "eval_duration": {
          "type": "integer",
          "description": "Time spent generating tokens in nanoseconds"
        }
      }
    },
    "ChatMessage": {
      "type": "object",
      "required": [
        "role",
        "content"
      ],
      "properties": {
        "role": {
          "type": "string",
          "enum": [
            "system",
            "user",
            "assistant",
            "tool"
          ],
          "description": "Author of the message."
        },
        "content": {
          "type": "string",
          "description": "Message text content"
        },
        "images": {
          "type": "array",
          "items": {
            "type": "string",
            "description": "Base64-encoded image content"
          },
          "description": "Optional list of inline images for multimodal models"
        },
        "tool_calls": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/ToolCall"
          },
          "description": "Tool call requests produced by the model"
        },
        "tool_name": {
          "type": "string",
          "description": "tool name"
        },
        "tool_call_id": {
          "type": "string",
          "description": "tool call id"
        }
      }
    },
    "ToolCall": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "description": "Tool call id"
        },
        "function": {
          "type": "object",
          "required": [
            "name"
          ],
          "properties": {
            "name": {
              "type": "string",
              "description": "Name of the function to call"
            },
            "description": {
              "type": "string",
              "description": "What the function does"
            },
            "arguments": {
              "type": "object",
              "description": "JSON object of arguments to pass to the function"
            }
          }
        }
      }
    },
    "ToolDefinition": {
      "type": "object",
      "required": [
        "type",
        "function"
      ],
      "properties": {
        "type": {
          "type": "string",
          "enum": [
            "function"
          ],
          "description": "Type of tool (always `function`)"
        },
        "function": {
          "type": "object",
          "required": [
            "name",
            "parameters"
          ],
          "properties": {
            "name": {
              "type": "string",
              "description": "Function name exposed to the model"
            },
            "description": {
              "type": "string",
              "description": "Human-readable description of the function"
            },
            "parameters": {
              "type": "object",
              "description": "JSON Schema for the function parameters"
            }
          }
        }
      }
    },
    "ChatRequest": {
      "type": "object",
      "required": [
        "model",
        "messages"
      ],
      "properties": {
        "model": {
          "type": "string",
          "description": "Model name"
        },
        "messages": {
          "type": "array",
          "description": "Chat history as an array of message objects (each with a role and content)",
          "items": {
            "$ref": "#/definitions/ChatMessage"
          }
        },
        "tools": {
          "type": "array",
          "description": "Optional list of function tools the model may call during the chat",
          "items": {
            "$ref": "#/definitions/ToolDefinition"
          }
        },
        "format": {
              "type": "object",
          "description": "Format to return a response in. Can be `json` or a JSON schema"
        },
        "options": {
          "$ref": "#/definitions/ModelOptions"
        },
        "stream": {
          "type": "boolean",
          "default": true
        },
        "think": {
              "type": "string",
              "enum": [
                "high",
                "medium",
                "low"
              ],
          "description": "When true, returns separate thinking output in addition to content. Can be a boolean (true/false) or a string (\"high\", \"medium\", \"low\") for supported models."
        },
        "keep_alive": {
              "type": "string",
          "description": "Model keep-alive duration (for example `5m` or `0` to unload immediately)"
        },
        "logprobs": {
          "type": "boolean",
          "description": "Whether to return log probabilities of the output tokens"
        },
        "top_logprobs": {
          "type": "integer",
          "description": "Number of most likely tokens to return at each token position when logprobs are enabled"
        }
      }
    },
    "ChatResponse": {
      "type": "object",
      "properties": {
        "model": {
          "type": "string",
          "description": "Model name used to generate this message"
        },
        "created_at": {
          "type": "string",
          "format": "date-time",
          "description": "Timestamp of response creation (ISO 8601)"
        },
        "message": {
          "type": "object",
          "properties": {
            "role": {
              "type": "string",
              "enum": [
                "assistant"
              ],
              "description": "Always `assistant` for model responses"
            },
            "content": {
              "type": "string",
              "description": "Assistant message text"
            },
            "thinking": {
              "type": "string",
              "description": "Optional deliberate thinking trace when `think` is enabled"
            },
            "tool_calls": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/ToolCall"
              },
              "description": "Tool calls requested by the assistant"
            },
            "images": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "Optional base64-encoded images in the response"
            }
          }
        },
        "done": {
          "type": "boolean",
          "description": "Indicates whether the chat response has finished"
        },
        "done_reason": {
          "type": "string",
          "description": "Reason the response finished"
        },
        "total_duration": {
          "type": "integer",
          "description": "Total time spent generating in nanoseconds"
        },
        "load_duration": {
          "type": "integer",
          "description": "Time spent loading the model in nanoseconds"
        },
        "prompt_eval_count": {
          "type": "integer",
          "description": "Number of tokens in the prompt"
        },
        "prompt_eval_duration": {
          "type": "integer",
          "description": "Time spent evaluating the prompt in nanoseconds"
        },
        "eval_count": {
          "type": "integer",
          "description": "Number of tokens generated in the response"
        },
        "eval_duration": {
          "type": "integer",
          "description": "Time spent generating tokens in nanoseconds"
        },
        "logprobs": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/Logprob"
          },
          "description": "Log probability information for the generated tokens when logprobs are enabled"
        }
      }
    },
    "ChatStreamEvent": {
      "type": "object",
      "properties": {
        "model": {
          "type": "string",
          "description": "Model name used for this stream event"
        },
        "created_at": {
          "type": "string",
          "format": "date-time",
          "description": "When this chunk was created (ISO 8601)"
        },
        "message": {
          "type": "object",
          "properties": {
            "role": {
              "type": "string",
              "description": "Role of the message for this chunk"
            },
            "content": {
              "type": "string",
              "description": "Partial assistant message text"
            },
            "thinking": {
              "type": "string",
              "description": "Partial thinking text when `think` is enabled"
            },
            "tool_calls": {
              "type": "array",
              "items": {
                "$ref": "#/definitions/ToolCall"
              },
              "description": "Partial tool calls, if any"
            },
            "images": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "Partial base64-encoded images, when present"
            }
          }
        },
        "done": {
          "type": "boolean",
          "description": "True for the final event in the stream"
        }
      }
    },
    "StatusEvent": {
      "type": "object",
      "properties": {
        "status": {
          "type": "string",
          "description": "Human-readable status message"
        },
        "digest": {
          "type": "string",
          "description": "Content digest associated with the status, if applicable"
        },
        "total": {
          "type": "integer",
          "description": "Total number of bytes expected for the operation"
        },
        "completed": {
          "type": "integer",
          "description": "Number of bytes transferred so far"
        }
      }
    },
    "StatusResponse": {
      "type": "object",
      "properties": {
        "status": {
          "type": "string",
          "description": "Current status message"
        }
      }
    },
    "EmbedRequest": {
      "type": "object",
      "required": [
        "model",
        "input"
      ],
      "properties": {
        "model": {
          "type": "string",
          "description": "Model name"
        },
        "input": {
              "type": "array",
              "items": {
                "type": "string"
              },
          "description": "Text or array of texts to generate embeddings for"
        },
        "truncate": {
          "type": "boolean",
          "default": true,
          "description": "If true, truncate inputs that exceed the context window. If false, returns an error."
        },
        "dimensions": {
          "type": "integer",
          "description": "Number of dimensions to generate embeddings for"
        },
        "keep_alive": {
          "type": "string",
          "description": "Model keep-alive duration"
        },
        "options": {
          "$ref": "#/definitions/ModelOptions"
        }
      }
    },
    "EmbedResponse": {
      "type": "object",
      "properties": {
        "model": {
          "type": "string",
          "description": "Model that produced the embeddings"
        },
        "embeddings": {
          "type": "array",
            "items": {
              "type": "number"
          },
          "description": "Array of vector embeddings"
        },
        "total_duration": {
          "type": "integer",
          "description": "Total time spent generating in nanoseconds"
        },
        "load_duration": {
          "type": "integer",
          "description": "Load time in nanoseconds"
        },
        "prompt_eval_count": {
          "type": "integer",
          "description": "Number of input tokens processed to generate embeddings"
        }
      }
    },
    "CreateRequest": {
      "type": "object",
      "required": [
        "model"
      ],
      "properties": {
        "model": {
          "type": "string",
          "description": "Name for the model to create"
        },
        "from": {
          "type": "string",
          "description": "Existing model to create from"
        },
        "template": {
          "type": "string",
          "description": "Prompt template to use for the model"
        },
        "license": {
              "type": "array",
              "items": {
                "type": "string"
              },
          "description": "License string or list of licenses for the model"
        },
        "system": {
          "type": "string",
          "description": "System prompt to embed in the model"
        },
        "parameters": {
          "type": "object",
          "description": "Key-value parameters for the model"
        },
        "messages": {
          "description": "Message history to use for the model",
          "type": "array",
          "items": {
            "$ref": "#/definitions/ChatMessage"
          }
        },
        "quantize": {
          "type": "string",
          "description": "Quantization level to apply (e.g. `q4_K_M`, `q8_0`)"
        },
        "stream": {
          "type": "boolean",
          "default": true,
          "description": "Stream status updates"
        }
      }
    },
    "CopyRequest": {
      "type": "object",
      "required": [
        "source",
        "destination"
      ],
      "properties": {
        "source": {
          "type": "string",
          "description": "Existing model name to copy from"
        },
        "destination": {
          "type": "string",
          "description": "New model name to create"
        }
      }
    },
    "DeleteRequest": {
      "type": "object",
      "required": [
        "model"
      ],
      "properties": {
        "model": {
          "type": "string",
          "description": "Model name to delete"
        }
      }
    },
    "PullRequest": {
      "type": "object",
      "required": [
        "model"
      ],
      "properties": {
        "model": {
          "type": "string",
          "description": "Name of the model to download"
        },
        "insecure": {
          "type": "boolean",
          "description": "Allow downloading over insecure connections"
        },
        "stream": {
          "type": "boolean",
          "default": true,
          "description": "Stream progress updates"
        }
      }
    },
    "PushRequest": {
      "type": "object",
      "required": [
        "model"
      ],
      "properties": {
        "model": {
          "type": "string",
          "description": "Name of the model to publish"
        },
        "insecure": {
          "type": "boolean",
          "description": "Allow publishing over insecure connections"
        },
        "stream": {
          "type": "boolean",
          "default": true,
          "description": "Stream progress updates"
        }
      }
    },
    "ShowRequest": {
      "type": "object",
      "required": [
        "model"
      ],
      "properties": {
        "model": {
          "type": "string",
          "description": "Model name to show"
        },
        "verbose": {
          "type": "boolean",
          "description": "If true, includes large verbose fields in the response."
        }
      }
    },
    "ShowResponse": {
      "type": "object",
      "properties": {
        "parameters": {
          "type": "string",
          "description": "Model parameter settings serialized as text"
        },
        "license": {
          "type": "string",
          "description": "The license of the model"
        },
        "modified_at": {
          "type": "string",
          "description": "Last modified timestamp in ISO 8601 format"
        },
        "details": {
          "type": "object",
          "description": "High-level model details"
        },
        "template": {
          "type": "string",
          "description": "The template used by the model to render prompts"
        },
        "capabilities": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "description": "List of supported features"
        },
        "model_info": {
          "type": "object",
          "description": "Additional model metadata"
        }
      }
    },
    "ModelSummary": {
      "type": "object",
      "description": "Summary information for a locally available model",
      "properties": {
        "name": {
          "type": "string",
          "description": "Model name"
        },
        "modified_at": {
          "type": "string",
          "description": "Last modified timestamp in ISO 8601 format"
        },
        "size": {
          "type": "integer",
          "description": "Total size of the model on disk in bytes"
        },
        "digest": {
          "type": "string",
          "description": "SHA256 digest identifier of the model contents"
        },
        "details": {
          "type": "object",
          "description": "Additional information about the model's format and family",
          "properties": {
            "format": {
              "type": "string",
              "description": "Model file format (for example `gguf`)"
            },
            "family": {
              "type": "string",
              "description": "Primary model family (for example `llama`)"
            },
            "families": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "All families the model belongs to, when applicable"
            },
            "parameter_size": {
              "type": "string",
              "description": "Approximate parameter count label (for example `7B`, `13B`)"
            },
            "quantization_level": {
              "type": "string",
              "description": "Quantization level used (for example `Q4_0`)"
            }
          }
        }
      }
    },
    "ListResponse": {
      "type": "object",
      "properties": {
        "models": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/ModelSummary"
          }
        }
      }
    },
    "Ps": {
      "type": "object",
      "properties": {
        "model": {
          "type": "string",
          "description": "Name of the running model"
        },
        "size": {
          "type": "integer",
          "description": "Size of the model in bytes"
        },
        "digest": {
          "type": "string",
          "description": "SHA256 digest of the model"
        },
        "details": {
          "type": "object",
          "description": "Model details such as format and family"
        },
        "expires_at": {
          "type": "string",
          "description": "Time when the model will be unloaded"
        },
        "size_vram": {
          "type": "integer",
          "description": "VRAM usage in bytes"
        },
        "context_length": {
          "type": "integer",
          "description": "Context length for the running model"
        }
      }
    },
    "PsResponse": {
      "type": "object",
      "properties": {
        "models": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/Ps"
          },
          "description": "Currently running models"
        }
      }
    },
    "WebSearchRequest": {
      "type": "object",
      "required": [
        "query"
      ],
      "properties": {
        "query": {
          "type": "string",
          "description": "Search query string"
        },
        "max_results": {
          "type": "integer",
          "minimum": 1,
          "maximum": 10,
          "default": 5,
          "description": "Maximum number of results to return"
        }
      }
    },
    "WebSearchResult": {
      "type": "object",
      "properties": {
        "title": {
          "type": "string",
          "description": "Page title of the result"
        },
        "url": {
          "type": "string",
          "format": "uri",
          "description": "Resolved URL for the result"
        },
        "content": {
          "type": "string",
          "description": "Extracted text content snippet"
        }
      }
    },
    "WebSearchResponse": {
      "type": "object",
      "properties": {
        "results": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/WebSearchResult"
          },
          "description": "Array of matching search results"
        }
      }
    },
    "WebFetchRequest": {
      "type": "object",
      "required": [
        "url"
      ],
      "properties": {
        "url": {
          "type": "string",
          "format": "uri",
          "description": "The URL to fetch"
        }
      }
    },
    "WebFetchResponse": {
      "type": "object",
      "properties": {
        "title": {
          "type": "string",
          "description": "Title of the fetched page"
        },
        "content": {
          "type": "string",
          "description": "Extracted page content"
        },
        "links": {
          "type": "array",
          "items": {
            "type": "string",
            "format": "uri"
          },
          "description": "Links found on the page"
        }
      }
    },
    "VersionResponse": {
      "type": "object",
      "properties": {
        "version": {
          "type": "string",
          "description": "Version of Ollama"
        }
      }
    },
    "TokenLogprob": {
      "type": "object",
      "description": "Log probability information for a single token alternative",
      "properties": {
        "token": {
          "type": "string",
          "description": "The text representation of the token"
        },
        "logprob": {
          "type": "number",
          "description": "The log probability of this token"
        },
        "bytes": {
          "type": "array",
          "items": {
            "type": "integer"
          },
          "description": "The raw byte representation of the token"
        }
      }
    },
    "Logprob": {
      "type": "object",
      "description": "Log probability information for a generated token",
      "properties": {
        "token": {
          "type": "string",
          "description": "The text representation of the token"
        },
        "logprob": {
          "type": "number",
          "description": "The log probability of this token"
        },
        "bytes": {
          "type": "array",
          "items": {
            "type": "integer"
          },
          "description": "The raw byte representation of the token"
        },
        "top_logprobs": {
          "type": "array",
          "items": {
            "$ref": "#/definitions/TokenLogprob"
          },
          "description": "Most likely tokens and their log probabilities at this position"
        }
      }
    },
    "ErrorResponse": {
      "type": "object",
      "properties": {
        "error": {
          "type": "string",
          "description": "Error message describing what went wrong"
        }
      }
    }
  }
}
